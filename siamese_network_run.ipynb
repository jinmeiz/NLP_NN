{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentences1</th>\n",
       "      <th>sentences2</th>\n",
       "      <th>is_similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         sentences1  \\\n",
       "0           0  What is the step by step guide to invest in sh...   \n",
       "1           1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2           2  How can I increase the speed of my internet co...   \n",
       "3           3  Why am I mentally very lonely? How can I solve...   \n",
       "4           4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                          sentences2  is_similar  \n",
       "0  What is the step by step guide to invest in sh...           0  \n",
       "1  What would happen if the Indian government sto...           0  \n",
       "2  How can Internet speed be increased by hacking...           0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...           0  \n",
       "4            Which fish would survive in salt water?           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('sample_data.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the step by step guide to invest in share market in india?', 'What is the story of Kohinoor (Koh-i-Noor) Diamond?']\n",
      "['What is the step by step guide to invest in share market?', 'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?']\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "s1_col = 'sentences1'\n",
    "s2_col = 'sentences2'\n",
    "label_col = 'is_similar'\n",
    "\n",
    "sentences1 = list(data[s1_col])\n",
    "sentences2 = list(data[s2_col])\n",
    "labels = list(data[label_col])\n",
    "\n",
    "print(sentences1[:2])\n",
    "print(sentences2[:2])\n",
    "print(labels[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india?'], ['what', 'is', 'the', 'story', 'of', 'kohinoor', '(koh-i-noor)', 'diamond?']]\n"
     ]
    }
   ],
   "source": [
    "documents = sentences1 + sentences2\n",
    "doc_words = [x.lower().split() for x in documents]\n",
    "print(doc_words[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_count: 998\n",
      "number of words: 3051\n",
      "total words+1:  3052\n",
      "Embedding matrix shape: (3052, 50)\n",
      "sample word embeddding:\n",
      "i 5\n",
      "[ 0.02492686  0.0723003  -0.071944   -0.07385619  0.12691942 -0.06671616\n",
      " -0.07998725  0.02979964  0.09013987 -0.1423238   0.04914633 -0.0373216\n",
      "  0.04891837  0.1338436   0.04649093 -0.05521586 -0.02145877  0.05603057\n",
      " -0.00115219  0.09226701  0.08108339 -0.03019674  0.06055864  0.07917215\n",
      " -0.14915016  0.14895718 -0.00683145  0.01768599  0.0021265   0.08286751\n",
      "  0.01430396  0.03134367 -0.1356062  -0.03298447  0.01094953  0.04307833\n",
      "  0.04760704 -0.05190314 -0.02534769 -0.10370425 -0.039808   -0.00392222\n",
      "  0.08980277  0.04625122 -0.14988358 -0.04670654 -0.0141106  -0.06206374\n",
      "  0.08177988  0.03772041]\n",
      "Null word embeddings: 1\n",
      "(449, 30) (25, 30) (25, 30)\n",
      "(449,) (25,) (25,)\n"
     ]
    }
   ],
   "source": [
    "from input_process_utils import tokenize_doc, obtain_word_embedding, input_process, create_train_valid_test_set\n",
    "\n",
    "# specify parameters\n",
    "embedding_dim = 50\n",
    "max_sentence_length = 30\n",
    "\n",
    "# tokenize words\n",
    "tokenizer = tokenize_doc(doc_words)\n",
    "nwords = len(tokenizer.word_index) + 1\n",
    "print('total words+1: ', nwords)\n",
    "\n",
    "# create word embedding matrix\n",
    "word_embedding_matrix = obtain_word_embedding(tokenizer, doc_words, embedding_dim)\n",
    "\n",
    "# convert sentences to list of tokens\n",
    "s1_padded_tokens, s2_padded_tokens = input_process(tokenizer, sentences1, sentences2, max_sentence_length)\n",
    "\n",
    "# create train, validation, test sets\n",
    "x1_train, x2_train, y_train, \\\n",
    "x1_valid, x2_valid, y_valid, \\\n",
    "x1_test, x2_test, y_test = create_train_valid_test_set(s1_padded_tokens, s2_padded_tokens, labels, test_size=0.1)\n",
    "\n",
    "print(x1_train.shape, x1_valid.shape, x1_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siamese_network import siamese_model\n",
    "\n",
    "# define parameters for model\n",
    "number_lstm_units = 100\n",
    "rate_drop_dense = 0.5\n",
    "number_dense_units = 100\n",
    "\n",
    "model_siamese = siamese_model(word_embedding_matrix, nwords, max_sentence_length,\n",
    "                              embedding_dim,\n",
    "                              number_lstm_units,\n",
    "                              number_dense_units, rate_drop_dense,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 50)       152600      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 200)          120800      embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "==================================================================================================\n",
      "Total params: 273,400\n",
      "Trainable params: 120,800\n",
      "Non-trainable params: 152,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jinmei/.pyenv/versions/3.6.5/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 449 samples, validate on 25 samples\n",
      "Epoch 1/10\n",
      "449/449 [==============================] - 2s 5ms/step - loss: 0.2791 - accuracy: 0.5412 - f1_metric: 0.4388 - val_loss: 0.1941 - val_accuracy: 0.7600 - val_f1_metric: 0.5714\n",
      "Epoch 2/10\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2658 - accuracy: 0.6013 - f1_metric: 0.3876 - val_loss: 0.1982 - val_accuracy: 0.7200 - val_f1_metric: 0.4615\n",
      "Epoch 3/10\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.5924 - f1_metric: 0.3708 - val_loss: 0.2007 - val_accuracy: 0.6800 - val_f1_metric: 0.5000\n",
      "Epoch 4/10\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2591 - accuracy: 0.5969 - f1_metric: 0.4129 - val_loss: 0.2036 - val_accuracy: 0.6400 - val_f1_metric: 0.4706\n",
      "Epoch 5/10\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2577 - accuracy: 0.5880 - f1_metric: 0.4103 - val_loss: 0.2033 - val_accuracy: 0.6800 - val_f1_metric: 0.5000\n",
      "Epoch 6/10\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2579 - accuracy: 0.6013 - f1_metric: 0.3925 - val_loss: 0.2059 - val_accuracy: 0.7600 - val_f1_metric: 0.5714\n",
      "Epoch 7/10\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2559 - accuracy: 0.6058 - f1_metric: 0.3887 - val_loss: 0.2036 - val_accuracy: 0.6400 - val_f1_metric: 0.4706\n",
      "Epoch 8/10\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2554 - accuracy: 0.5969 - f1_metric: 0.3589 - val_loss: 0.2071 - val_accuracy: 0.7200 - val_f1_metric: 0.3636\n",
      "Epoch 9/10\n",
      "449/449 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.6036 - f1_metric: 0.3619 - val_loss: 0.2042 - val_accuracy: 0.6400 - val_f1_metric: 0.4706\n",
      "Epoch 10/10\n",
      "449/449 [==============================] - 1s 3ms/step - loss: 0.2540 - accuracy: 0.6058 - f1_metric: 0.4063 - val_loss: 0.2036 - val_accuracy: 0.6800 - val_f1_metric: 0.4286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x12a027588>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_siamese.fit([x1_train, x2_train], y_train,\n",
    "                  validation_data=([x1_valid, x2_valid], y_valid),\n",
    "                  epochs=10, batch_size=32, shuffle=True,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'siamese_model.h5'\n",
    "\n",
    "model_siamese.save(model_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from siamese_network import exponent_neg_manhattan_distance, f1_metric\n",
    "\n",
    "model_file = 'siamese_model.h5'\n",
    "model = load_model(model_file, \n",
    "                   custom_objects={'exponent_neg_manhattan_distance': exponent_neg_manhattan_distance,\n",
    "                                   'f1_metric': f1_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.classification import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_pred = model.predict([x1_test, x2_test], verbose=1)\n",
    "y_test_pred_classes = [round(y[0]) for y in y_test_pred.tolist()]\n",
    "\n",
    "print('accuracy:', accuracy_score(y_test, y_test_pred_classes))\n",
    "\n",
    "# precision:    shape = [n_unique_labels]\n",
    "# recall:       shape = [n_unique_labels]\n",
    "# fbeta_score:  shape = [n_unique_labels]\n",
    "precision_recall_fscore_support(y_test, y_valid_test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.5273507237434387]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.49098411202430725]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.5263671875]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.1259659081697464]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.44758933782577515]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                   prob  pred\n",
       "0      0   [0.5273507237434387]     1\n",
       "1      1  [0.49098411202430725]     0\n",
       "2      1         [0.5263671875]     1\n",
       "3      1   [0.1259659081697464]     0\n",
       "4      0  [0.44758933782577515]     0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = pd.DataFrame({'label':y_test, 'prob':y_test_pred.tolist(), 'pred':y_test_pred_classes})\n",
    "comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp[comp['label'] != comp['pred']].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "200.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
