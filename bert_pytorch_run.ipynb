{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T04:53:56.897024Z",
     "start_time": "2019-08-30T04:53:44.777420Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install torch==1.2.0+cpu torchvision==0.4.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T04:54:02.139577Z",
     "start_time": "2019-08-30T04:53:59.354187Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:16:43.446244Z",
     "start_time": "2019-08-30T18:16:42.042708Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# text column is the feature column, label column is the target column\n",
    "train_data_pd = pd.read_csv(open('train_data.csv','r'))\n",
    "train_data_pd = train_data_pd[train_data_pd['text'].notnull()\n",
    "                              & train_data_pd['label'].notnull()\n",
    "                             ]                        \n",
    "print(\"train data:\", train_data_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:17:26.317961Z",
     "start_time": "2019-08-30T18:17:26.313556Z"
    }
   },
   "outputs": [],
   "source": [
    "len(truncated_doc_icx)/len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:17:29.851275Z",
     "start_time": "2019-08-30T18:17:29.834525Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame({\n",
    "    'id':range(len(train_data_pd)),\n",
    "    'label':train_data_pd['label'],\n",
    "    'alpha':['a']*train_data_pd.shape[0],\n",
    "    'text': list(train_data_pd.text)\n",
    "})\n",
    "train_df['label'] = train_df.label.astype(int)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:20:37.089857Z",
     "start_time": "2019-08-30T18:20:37.081143Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df_bert, dev_df_bert = train_test_split(train_df, test_size=0.3, random_state=42)\n",
    "print(train_df_bert.shape, dev_df_bert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:21:08.298373Z",
     "start_time": "2019-08-30T18:21:05.821878Z"
    }
   },
   "outputs": [],
   "source": [
    "# make sure columns are in right order, as they are hard coded in the process code\n",
    "train_df_bert[cols].to_csv('./data_pytorch/train.tsv', sep='\\t', index=False, header=False)\n",
    "dev_df_bert[cols].to_csv('./data_pytorch/dev.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:21:27.753533Z",
     "start_time": "2019-08-30T18:21:27.211620Z"
    }
   },
   "outputs": [],
   "source": [
    "from ml.models.relevancy_geography.v3_0_0.bert_utils import BinaryClassificationProcessor\n",
    "\n",
    "DATA_DIR = './data_pytorch/'\n",
    "\n",
    "processor = BinaryClassificationProcessor()\n",
    "\n",
    "train_examples = processor.get_train_examples(DATA_DIR)\n",
    "train_examples_len = len(train_examples)\n",
    "print('train_examples_len:', train_examples_len)\n",
    "\n",
    "label_list = processor.get_labels() # [0, 1] for binary classification\n",
    "num_labels = len(label_list)\n",
    "print('num_labels:', num_labels)\n",
    "\n",
    "label_map = {label: i for i, label in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:21:30.744551Z",
     "start_time": "2019-08-30T18:21:30.385861Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "\n",
    "# Bert pre-trained model selected in the list: bert-base-uncased, \n",
    "# bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,\n",
    "# bert-base-multilingual-cased, bert-base-chinese.\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:24:39.423310Z",
     "start_time": "2019-08-30T18:21:33.178515Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm.auto import tqdm\n",
    "from ml.models.relevancy_geography.v3_0_0.bert_utils import convert_example_to_feature\n",
    "\n",
    "MAX_SEQ_LENGTH = 512 # maximum for bert model\n",
    "OUTPUT_MODE = 'classification'\n",
    "\n",
    "train_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) \n",
    "                                 for example in train_examples]\n",
    "\n",
    "process_count = cpu_count() - 2\n",
    "print(f'Preparing to convert {train_examples_len} examples..')\n",
    "print(f'Spawning {process_count} processes..')\n",
    "with Pool(process_count) as p:\n",
    "    train_features = list(tqdm(p.imap(convert_example_to_feature, train_examples_for_processing), \n",
    "                               total=train_examples_len)\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:26:57.170179Z",
     "start_time": "2019-08-30T18:26:55.335456Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(DATA_DIR + \"train_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:27:00.366355Z",
     "start_time": "2019-08-30T18:26:58.884554Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "DATA_DIR = './data_pytorch/'\n",
    "\n",
    "with open(DATA_DIR + \"train_features.pkl\", \"rb\") as f:\n",
    "    train_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T16:53:40.227966Z",
     "start_time": "2019-08-27T16:53:40.151931Z"
    }
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:27:44.164167Z",
     "start_time": "2019-08-30T18:27:35.235599Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertForSequenceClassification\n",
    "\n",
    "# This is where BERT will look for pre-trained models to load parameters from.\n",
    "CACHE_DIR = './cache/'\n",
    "\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "\n",
    "num_labels = 2\n",
    "# Load pre-trained model (weights)\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, cache_dir=CACHE_DIR, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T16:04:36.099304Z",
     "start_time": "2019-08-28T16:04:36.048263Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:27:50.090293Z",
     "start_time": "2019-08-30T18:27:50.062844Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "\n",
    "# optimizer\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "LEARNING_RATE = 2e-5\n",
    "WARMUP_PROPORTION = 0.1\n",
    "\n",
    "train_examples_len = len(train_features)\n",
    "    \n",
    "num_train_optimization_steps = int(\n",
    "    train_examples_len / TRAIN_BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS) * NUM_TRAIN_EPOCHS\n",
    "print('num_train_optimization_steps', num_train_optimization_steps)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=LEARNING_RATE,\n",
    "                     warmup=WARMUP_PROPORTION,\n",
    "                     t_total=num_train_optimization_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T18:27:54.777868Z",
     "start_time": "2019-08-30T18:27:54.420939Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, TensorDataset\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", train_examples_len)\n",
    "logger.info(\"  Batch size = %d\", TRAIN_BATCH_SIZE)\n",
    "logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "\n",
    "OUTPUT_MODE = 'classification'\n",
    "if OUTPUT_MODE == \"classification\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "elif OUTPUT_MODE == \"regression\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.float)\n",
    "    \n",
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-30T18:29:06.478Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "\n",
    "model.train()\n",
    "\n",
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0\n",
    "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
    "\n",
    "        if OUTPUT_MODE == \"classification\":\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "        elif OUTPUT_MODE == \"regression\":\n",
    "            loss_fct = MSELoss()\n",
    "            loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "\n",
    "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "        loss.backward()\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-30T22:33:38.111Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "\n",
    "# The output directory where the fine-tuned model and checkpoints will be written.\n",
    "OUTPUT_DIR = f'./outputs/{TASK_NAME}/'\n",
    "\n",
    "# The name of the task to train.\n",
    "TASK_NAME = 'task_pytorch'\n",
    "\n",
    "CONFIG_NAME = \"bert_config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\"\n",
    "\n",
    "# If we save using the predefined names, we can load using `from_pretrained`\n",
    "output_model_file = os.path.join(OUTPUT_DIR, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(OUTPUT_DIR, CONFIG_NAME)\n",
    "\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-30T22:33:41.705Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "\n",
    "# Bert pre-trained model selected in the list: bert-base-uncased, \n",
    "# bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,\n",
    "# bert-base-multilingual-cased, bert-base-chinese.\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=False)\n",
    "tokenizer.save_vocabulary(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T15:01:38.245632Z",
     "start_time": "2019-08-30T15:01:03.421601Z"
    }
   },
   "outputs": [],
   "source": [
    "!tar -cvzf ./cache/task_pytorch.tar.gz -C ./outputs/task_pytorch bert_config.json pytorch_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T16:57:33.403690Z",
     "start_time": "2019-08-30T16:57:33.189953Z"
    }
   },
   "outputs": [],
   "source": [
    "from ml.models.relevancy_geography.v3_0_0.bert_utils import BinaryClassificationProcessor\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "OUTPUT_DIR = f'./outputs/{TASK_NAME}/'\n",
    "tokenizer = BertTokenizer.from_pretrained(OUTPUT_DIR + 'vocab.txt', do_lower_case=False)\n",
    "\n",
    "processor = BinaryClassificationProcessor()\n",
    "eval_examples = processor.get_dev_examples(DATA_DIR)\n",
    "\n",
    "label_list = processor.get_labels() # [0, 1] for binary classification\n",
    "num_labels = len(label_list)\n",
    "\n",
    "eval_examples_len = len(eval_examples)\n",
    "print('number of examples for evaluation:', eval_examples_len)\n",
    "\n",
    "MAX_SEQ_LENGTH = 512\n",
    "OUTPUT_MODE = 'classification'\n",
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "eval_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in eval_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T16:57:45.989493Z",
     "start_time": "2019-08-30T16:57:36.804443Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm.auto import tqdm\n",
    "from ml.models.relevancy_geography.v3_0_0.bert_utils import convert_example_to_feature\n",
    "\n",
    "process_count = cpu_count() - 1\n",
    "\n",
    "print(f'Preparing to convert {eval_examples_len} examples..')\n",
    "print(f'Spawning {process_count} processes..')\n",
    "with Pool(process_count) as p:\n",
    "    eval_features = list(tqdm(p.imap(convert_example_to_feature, eval_examples_for_processing), \n",
    "                              total=eval_examples_len)\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T15:08:33.701774Z",
     "start_time": "2019-08-30T15:08:25.499114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "CACHE_DIR = './cache/'\n",
    "CURR_BERT_MODEL = 'task_pytorch.tar.gz'\n",
    "\n",
    "curr_model = BertForSequenceClassification.from_pretrained(CACHE_DIR + CURR_BERT_MODEL, cache_dir=CACHE_DIR, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T16:57:48.790423Z",
     "start_time": "2019-08-30T16:57:48.753820Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "\n",
    "if OUTPUT_MODE == \"classification\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "elif OUTPUT_MODE == \"regression\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.float)\n",
    "\n",
    "eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "# Run prediction for full data\n",
    "EVAL_BATCH_SIZE = 8\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T15:10:58.380590Z",
     "start_time": "2019-08-30T15:10:58.370063Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "\n",
    "def get_eval_report(task_name, labels, preds):\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    return {\n",
    "        \"task\": task_name,\n",
    "        \"mcc\": mcc,\n",
    "        \"tp\": tp,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn\n",
    "    }\n",
    "\n",
    "def compute_metrics(task_name, labels, preds):\n",
    "    assert len(preds) == len(labels)\n",
    "    return get_eval_report(task_name, labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T17:03:18.208385Z",
     "start_time": "2019-08-30T16:57:51.510395Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "curr_model.eval()\n",
    "eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "preds = []\n",
    "\n",
    "for input_ids, input_mask, segment_ids, label_ids in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    label_ids = label_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = curr_model(input_ids, segment_ids, input_mask, labels=None)\n",
    "\n",
    "    # create eval loss and other metric required by the task\n",
    "    if OUTPUT_MODE == \"classification\":\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "    elif OUTPUT_MODE == \"regression\":\n",
    "        loss_fct = MSELoss()\n",
    "        tmp_eval_loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "\n",
    "    eval_loss += tmp_eval_loss.mean().item()\n",
    "    nb_eval_steps += 1\n",
    "    if len(preds) == 0:\n",
    "        preds.append(logits.detach().cpu().numpy())\n",
    "    else:\n",
    "        preds[0] = np.append(\n",
    "            preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "eval_loss = eval_loss / nb_eval_steps\n",
    "preds = preds[0]\n",
    "if OUTPUT_MODE == \"classification\":\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "elif OUTPUT_MODE == \"regression\":\n",
    "    preds = np.squeeze(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T17:03:53.336580Z",
     "start_time": "2019-08-30T17:03:53.140396Z"
    }
   },
   "outputs": [],
   "source": [
    "result = compute_metrics(TASK_NAME, all_label_ids.numpy(), preds)\n",
    "\n",
    "result['eval_loss'] = eval_loss\n",
    "\n",
    "# The directory where the evaluation reports will be written to.\n",
    "REPORTS_DIR = f'./reports/{TASK_NAME}_evaluation_report/'\n",
    "output_eval_file = os.path.join(REPORTS_DIR, \"eval_results_add_sample_holdout.txt\")\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    logger.info(\"***** Eval results *****\")\n",
    "    for key in (result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T17:04:03.611375Z",
     "start_time": "2019-08-30T17:04:03.604160Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.classification import precision_recall_fscore_support\n",
    "\n",
    "precision_recall_fscore_support(all_label_ids.numpy(), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T16:21:26.839866Z",
     "start_time": "2019-08-30T16:21:26.599241Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "holdout_data_raw = pd.read_csv('holdout_data.csv')\n",
    "holdout_data_pd = holdout_data_raw[(holdout_data_raw['text'].str.len().notnull())\n",
    "                                   & holdout_data_raw['label'].notnull()\n",
    "                                   ] \n",
    "print(\"holdout data:\", holdout_data_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T16:34:43.398488Z",
     "start_time": "2019-08-30T16:34:43.383496Z"
    }
   },
   "outputs": [],
   "source": [
    "holdout_bert = pd.DataFrame({\n",
    "    'id':range(len(holdout_data_pd)),\n",
    "    'label':holdout_data_pd['label'],\n",
    "    'alpha':['a']*holdout_data_pd.shape[0],\n",
    "    'text': list(holdout_data_pd.text)\n",
    "})\n",
    "holdout_bert['label'] = holdout_bert.label.astype(int)\n",
    "print(holdout_bert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T16:35:17.238531Z",
     "start_time": "2019-08-30T16:35:16.764544Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['id', 'label', 'alpha', 'text']\n",
    "holdout_bert[cols].to_csv('./data_pytorch/holdout.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "704px",
    "left": "0px",
    "right": "1228px",
    "top": "110px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
